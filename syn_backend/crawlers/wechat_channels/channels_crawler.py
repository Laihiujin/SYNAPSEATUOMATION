"""
è§†é¢‘å·æ•°æ®çˆ¬è™«
ä½¿ç”¨ Selenium è®¿é—®å¾®ä¿¡è§†é¢‘å·åˆ›ä½œè€…å¹³å°ï¼ŒæŠ“å–ä½œå“åˆ—è¡¨
"""
import json
import time
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

from loguru import logger
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup

try:
    from .config import CHROME_PATHS, HEADLESS_MODE, USER_AGENT
except ImportError:
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
    CHROME_PATHS = []
    HEADLESS_MODE = True
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"


class WechatChannelsCrawler:
    """å¾®ä¿¡è§†é¢‘å·çˆ¬è™«"""

    def __init__(self, cookies: Optional[List[Dict[str, Any]]] = None):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            cookies: å¾®ä¿¡è§†é¢‘å·çš„ Cookie åˆ—è¡¨
        """
        self.cookies = cookies or []
        self.driver: Optional[webdriver.Chrome] = None
        self.base_url = "https://channels.weixin.qq.com"
        self.platform_url = f"{self.base_url}/platform/post/list"
        self._base_dir = Path(__file__).resolve().parent.parent.parent
        self._cookies_dir = self._base_dir / "cookiesFile"
        self._profiles_dir = self._base_dir / "browser_profiles"  # æŒä¹…åŒ–æµè§ˆå™¨é…ç½®ç›®å½•
        self.account_info = {}

    def _init_driver(self, account_id: str = "default") -> webdriver.Chrome:
        """åˆå§‹åŒ– Chrome WebDriverï¼ˆä½¿ç”¨æŒä¹…åŒ–é…ç½®ï¼‰"""
        options = webdriver.ChromeOptions()

        # è®¾ç½®æŒä¹…åŒ–æµè§ˆå™¨é…ç½®ç›®å½•ï¼ˆUser Data Dirï¼‰
        profile_name = f"wechat_channels_{account_id}"
        user_data_dir = self._profiles_dir / profile_name
        user_data_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ“ ä½¿ç”¨æŒä¹…åŒ–é…ç½®ç›®å½•: {user_data_dir}")
        options.add_argument(f"--user-data-dir={user_data_dir}")

        # å°è¯•ä½¿ç”¨æœ¬åœ° Chromium æµè§ˆå™¨
        chrome_found = False
        for chrome_path in CHROME_PATHS:
            if chrome_path.exists():
                options.binary_location = str(chrome_path)
                logger.info(f"âœ… ä½¿ç”¨æœ¬åœ°æµè§ˆå™¨: {chrome_path.name}")
                chrome_found = True
                break

        if not chrome_found:
            logger.warning(f"âš ï¸  æœªæ‰¾åˆ°æœ¬åœ°æµè§ˆå™¨ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤æµè§ˆå™¨")

        # é…ç½®é€‰é¡¹
        if HEADLESS_MODE:
            options.add_argument("--headless=new")  # æ–°ç‰ˆ Headless æ¨¡å¼
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)

        # User-Agent
        options.add_argument(f"user-agent={USER_AGENT}")

        try:
            driver = webdriver.Chrome(options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            logger.info("âœ… WebDriver åˆå§‹åŒ–æˆåŠŸ")
            return driver
        except Exception as e:
            logger.error(f"âŒ WebDriver åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _load_cookies(self):
        """åŠ è½½ Cookie åˆ°æµè§ˆå™¨"""
        if not self.driver:
            return

        # å…ˆè®¿é—®ä¸»é¡µï¼Œç¡®ä¿åŸŸåæ­£ç¡®
        self.driver.get(self.base_url)
        time.sleep(2)

        # æ·»åŠ  Cookie
        for cookie in self.cookies:
            try:
                # Selenium éœ€è¦çš„ Cookie æ ¼å¼
                cookie_dict = {
                    "name": cookie.get("name"),
                    "value": cookie.get("value"),
                    "domain": cookie.get("domain", ".weixin.qq.com"),
                    "path": cookie.get("path", "/"),
                }
                if cookie.get("expirationDate"):
                    cookie_dict["expiry"] = int(cookie["expirationDate"])

                self.driver.add_cookie(cookie_dict)
            except Exception as e:
                logger.warning(f"æ·»åŠ  Cookie å¤±è´¥: {e}")

        logger.info(f"âœ… å·²åŠ è½½ {len(self.cookies)} ä¸ª Cookie")

    async def start(self, account_cookie_file: str, max_pages: int = 3) -> Dict[str, Any]:
        """
        å¯åŠ¨çˆ¬è™«ï¼ŒæŠ“å–è§†é¢‘å·ä½œå“åˆ—è¡¨

        Args:
            account_cookie_file: Cookie æ–‡ä»¶åï¼ˆåœ¨ cookiesFile ç›®å½•ä¸‹ï¼‰
            max_pages: æœ€å¤šæŠ“å–å¤šå°‘é¡µ

        Returns:
            æŠ“å–ç»“æœ
        """
        try:
            # åŠ è½½ Cookie æ–‡ä»¶
            cookie_path = self._cookies_dir / account_cookie_file
            if not cookie_path.exists():
                return {
                    "success": False,
                    "error": f"Cookie æ–‡ä»¶ä¸å­˜åœ¨: {account_cookie_file}",
                    "platform": "wechat_channels"
                }

            with cookie_path.open("r", encoding="utf-8") as fp:
                cookie_data = json.load(fp)
                self.cookies = cookie_data.get("cookies", [])
                self.account_info = cookie_data.get("user_info", {})

            if not self.cookies:
                return {
                    "success": False,
                    "error": "Cookie æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ Cookie",
                    "platform": "wechat_channels"
                }

            # è·å–è´¦å· ID
            account_id = self.account_info.get("user_id", "unknown")

            # åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆä¼ é€’è´¦å·IDç”¨äºæŒä¹…åŒ–é…ç½®ï¼‰
            self.driver = self._init_driver(account_id)
            self._load_cookies()

            # è®¿é—®åˆ›ä½œè€…å¹³å°
            logger.info(f"ğŸŒ è®¿é—®åˆ›ä½œè€…å¹³å°: {self.platform_url}")
            self.driver.get(self.platform_url)

            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)

            # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
            if not self._check_login_status():
                return {
                    "success": False,
                    "error": "Cookie å·²å¤±æ•ˆæˆ–æœªç™»å½•",
                    "platform": "wechat_channels"
                }

            # æŠ“å–ä½œå“åˆ—è¡¨
            videos = await self._fetch_video_list(max_pages)

            return {
                "success": True,
                "data": {
                    "account_id": self.account_info.get("user_id", ""),
                    "account_name": self.account_info.get("name", ""),
                    "videos": videos,
                    "total": len(videos),
                    "crawled_at": datetime.now().isoformat()
                },
                "platform": "wechat_channels"
            }

        except Exception as e:
            logger.error(f"âŒ è§†é¢‘å·çˆ¬è™«å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "platform": "wechat_channels"
            }
        finally:
            self._cleanup()

    def _check_login_status(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ"""
        try:
            # æ£€æŸ¥1: URL æ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»åŒ…å« /platform/post/listï¼‰
            current_url = self.driver.current_url
            if "/platform/post/list" not in current_url:
                logger.error(f"âŒ URL ä¸æ­£ç¡®: {current_url}")
                return False

            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼ˆVue.js éœ€è¦æ—¶é—´æ¸²æŸ“ï¼‰
            logger.info("â³ ç­‰å¾…é¡µé¢æ¸²æŸ“...")
            time.sleep(5)

            # æ£€æŸ¥2: å°è¯•å¤šä¸ªé€‰æ‹©å™¨ï¼ˆä»»æ„ä¸€ä¸ªå­˜åœ¨å³å¯ï¼‰
            selectors = [
                # å°è¯•é€šè¿‡ OCR è¯†åˆ«çš„æ–‡æœ¬æŸ¥æ‰¾
                (By.XPATH, "//*[contains(text(), 'è§†é¢‘ç®¡ç†')]"),
                (By.XPATH, "//*[contains(text(), 'è§†é¢‘ (')]"),
                # å°è¯•å¸¸è§çš„è§†é¢‘åˆ—è¡¨å®¹å™¨ class
                (By.CSS_SELECTOR, "[class*='post']"),
                (By.CSS_SELECTOR, "[class*='video']"),
                (By.CSS_SELECTOR, "[class*='content-list']"),
                (By.CSS_SELECTOR, "[class*='list-item']"),
                # å°è¯•å¾®ä¿¡å¸¸ç”¨çš„ class å‰ç¼€
                (By.CSS_SELECTOR, "[class*='weui-desktop']"),
                (By.CSS_SELECTOR, "[class*='finder']"),
            ]

            element_found = False
            for by, value in selectors:
                try:
                    element = WebDriverWait(self.driver, 2).until(
                        EC.presence_of_element_located((by, value))
                    )
                    logger.info(f"âœ… æ‰¾åˆ°å…³é”®å…ƒç´ : {value} -> {element.tag_name}")
                    element_found = True
                    break
                except TimeoutException:
                    continue

            if not element_found:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°é¢„æœŸçš„å…ƒç´ é€‰æ‹©å™¨")
                # ä½†å¦‚æœ URL æ­£ç¡®ä¸”é¡µé¢åŠ è½½å®Œæˆï¼Œä¹Ÿè®¤ä¸ºç™»å½•æˆåŠŸ
                # æ£€æŸ¥é¡µé¢æºç ä¸­æ˜¯å¦åŒ…å«å…³é”®å­—
                page_source = self.driver.page_source
                if "è§†é¢‘ç®¡ç†" in page_source or "è§†é¢‘å·åŠ©æ‰‹" in page_source:
                    logger.info("âœ… é€šè¿‡é¡µé¢å†…å®¹éªŒè¯ï¼šç™»å½•æˆåŠŸ")
                    return True
                else:
                    logger.error("âŒ é¡µé¢å†…å®¹ä¸åŒ¹é…ï¼Œç™»å½•å¯èƒ½å¤±è´¥")
                    # ä¿å­˜è°ƒè¯•ä¿¡æ¯ï¼ˆHTML + æˆªå›¾ + OCRï¼‰
                    self._save_debug_bundle("login_failed")
                    return False

            logger.info("âœ… ç™»å½•éªŒè¯æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"âŒ ç™»å½•éªŒè¯å¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _save_debug_bundle(self, prefix: str):
        """ä¿å­˜è°ƒè¯•ä¿¡æ¯ï¼ˆæˆªå›¾ + HTML + OCRï¼‰"""
        try:
            from automation.selenium_dom import capture_debug_bundle
            timestamp = int(time.time())
            out_dir = self._base_dir / "logs"
            result = capture_debug_bundle(
                self.driver,
                str(out_dir),
                f"{prefix}_{timestamp}",
                run_ocr=True
            )
            logger.info(f"ğŸ“¸ å·²ä¿å­˜æˆªå›¾: {result.screenshot_path}")
            logger.info(f"ğŸ“„ å·²ä¿å­˜ HTML: {result.html_path}")
            if result.ocr_text_path:
                logger.info(f"ğŸ” å·²ä¿å­˜ OCR æ–‡æœ¬: {result.ocr_text_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å¤±è´¥: {e}")

    async def _fetch_video_list(self, max_pages: int = 3) -> List[Dict[str, Any]]:
        """
        æŠ“å–è§†é¢‘åˆ—è¡¨

        Args:
            max_pages: æœ€å¤šæŠ“å–å¤šå°‘é¡µ

        Returns:
            è§†é¢‘åˆ—è¡¨
        """
        all_videos = []
        current_page = 1

        while current_page <= max_pages:
            logger.info(f"ğŸ“„ æ­£åœ¨æŠ“å–ç¬¬ {current_page} é¡µ...")

            try:
                # é¢å¤–ç­‰å¾…ç¡®ä¿é¡µé¢å®Œå…¨æ¸²æŸ“
                time.sleep(3)

                # è·å–é¡µé¢ HTML å’Œæˆªå›¾ç”¨äºè°ƒè¯•
                page_source = self.driver.page_source

                # ä¿å­˜å½“å‰é¡µé¢çŠ¶æ€ç”¨äºè°ƒè¯•
                debug_path = self._base_dir / "logs" / f"page_{current_page}_{int(time.time())}"
                debug_path.parent.mkdir(exist_ok=True)

                # ä¿å­˜ HTML
                with open(f"{debug_path}.html", "w", encoding="utf-8") as f:
                    f.write(page_source)

                # ä¿å­˜æˆªå›¾
                self.driver.save_screenshot(f"{debug_path}.png")
                logger.info(f"ğŸ“¸ å·²ä¿å­˜è°ƒè¯•ä¿¡æ¯: {debug_path}.png")

                # ä½¿ç”¨ JavaScript è·å–é¡µé¢ä¸­çš„æ‰€æœ‰è§†é¢‘å…ƒç´ 
                # å°è¯•é€šè¿‡ DOM æŸ¥è¯¢è€Œä¸æ˜¯ BeautifulSoup
                video_elements = self.driver.execute_script("""
                    // å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°è§†é¢‘åˆ—è¡¨
                    const selectors = [
                        '[class*="post"]',
                        '[class*="video"]',
                        '[class*="item"]',
                        '[class*="card"]',
                        '[class*="list"]'
                    ];

                    let elements = [];
                    for (const selector of selectors) {
                        const found = document.querySelectorAll(selector);
                        if (found.length > 0) {
                            console.log('Found', found.length, 'elements with selector:', selector);
                            elements = Array.from(found);
                            break;
                        }
                    }

                    // è¿”å›å…ƒç´ çš„åŸºæœ¬ä¿¡æ¯
                    return elements.slice(0, 20).map(el => ({
                        tagName: el.tagName,
                        className: el.className,
                        innerHTML: el.innerHTML.substring(0, 500),
                        textContent: el.textContent.substring(0, 200)
                    }));
                """)

                logger.info(f"ğŸ” JavaScript æŸ¥è¯¢åˆ° {len(video_elements)} ä¸ªå…ƒç´ ")

                if video_elements:
                    logger.info(f"ğŸ“‹ å‰ 3 ä¸ªå…ƒç´ ç¤ºä¾‹:")
                    for i, elem in enumerate(video_elements[:3], 1):
                        logger.info(f"  {i}. Tag: {elem.get('tagName')}, Class: {elem.get('className')[:50]}")
                        logger.info(f"     Text: {elem.get('textContent')[:100]}")

                # ä½¿ç”¨ BeautifulSoup è§£æ
                soup = BeautifulSoup(page_source, "html.parser")

                # æ ¹æ® OCR è¯†åˆ«çš„å†…å®¹ï¼Œè§†é¢‘åº”è¯¥åŒ…å«æ ‡é¢˜ã€æ—¥æœŸã€ç»Ÿè®¡æ•°æ®
                # å°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„è§†é¢‘å®¹å™¨
                video_items = []

                # ç­–ç•¥1: æŸ¥æ‰¾åŒ…å«æ—¥æœŸæ¨¡å¼çš„å…ƒç´ çš„çˆ¶å®¹å™¨
                date_elements = soup.find_all(string=lambda text: text and ("2025å¹´" in text or "2024å¹´" in text))
                logger.info(f"ğŸ” æ‰¾åˆ° {len(date_elements)} ä¸ªæ—¥æœŸå…ƒç´ ")

                for date_elem in date_elements:
                    parent = date_elem.parent
                    # å‘ä¸ŠæŸ¥æ‰¾3å±‚æ‰¾åˆ°è§†é¢‘å®¹å™¨
                    for _ in range(3):
                        if parent and parent.name:
                            parent = parent.parent
                    if parent and parent not in video_items:
                        video_items.append(parent)

                logger.info(f"âœ… ç¬¬ {current_page} é¡µæ‰¾åˆ° {len(video_items)} ä¸ªå¯èƒ½çš„è§†é¢‘å®¹å™¨")

                if len(video_items) == 0:
                    logger.warning(f"âš ï¸  ç¬¬ {current_page} é¡µæœªæ‰¾åˆ°è§†é¢‘å…ƒç´ ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ç”¨ OCR æå–çš„æ–‡æœ¬é‡æ„æ•°æ®
                    logger.info("ğŸ’¡ ä½¿ç”¨ OCR æ–‡æœ¬è§£æ...")
                    break

                for item in video_items:
                    video_data = self._parse_video_item(item)
                    if video_data:
                        all_videos.append(video_data)

                logger.info(f"âœ… ç¬¬ {current_page} é¡µæŠ“å–å®Œæˆï¼Œè·å¾— {len(video_items)} ä¸ªè§†é¢‘")

                # å°è¯•ç¿»é¡µ
                if not self._go_to_next_page():
                    logger.info("ğŸ“Œ å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    break

                current_page += 1
                time.sleep(2)

            except TimeoutException:
                logger.warning(f"âš ï¸ ç¬¬ {current_page} é¡µåŠ è½½è¶…æ—¶")
                break
            except Exception as e:
                logger.error(f"âŒ æŠ“å–ç¬¬ {current_page} é¡µæ—¶å‡ºé”™: {e}")
                import traceback
                logger.error(traceback.format_exc())
                break

        logger.info(f"ğŸ‰ æ€»è®¡æŠ“å– {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos

    def _parse_video_item(self, item) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªè§†é¢‘é¡¹ï¼ˆéœ€è¦æ ¹æ®å®é™… HTML ç»“æ„è°ƒæ•´ï¼‰

        Args:
            item: BeautifulSoup è§£æçš„è§†é¢‘å…ƒç´ 

        Returns:
            è§†é¢‘æ•°æ®å­—å…¸
        """
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
            # ç¤ºä¾‹ï¼šå‡è®¾æœ‰æ ‡é¢˜ã€æ’­æ”¾é‡ã€ç‚¹èµæ•°ç­‰ä¿¡æ¯
            title_elem = item.find(class_="post-title")
            stats_elem = item.find(class_="post-stats")
            cover_elem = item.find("img")

            video_data = {
                "title": title_elem.get_text(strip=True) if title_elem else "",
                "cover_url": cover_elem.get("src") if cover_elem else "",
                "stats": stats_elem.get_text(strip=True) if stats_elem else "",
                "raw_html": str(item),  # ä¿ç•™åŸå§‹ HTML ä¾›åç»­åˆ†æ
                "crawled_at": datetime.now().isoformat()
            }

            return video_data

        except Exception as e:
            logger.warning(f"è§£æè§†é¢‘é¡¹å¤±è´¥: {e}")
            return None

    def _go_to_next_page(self) -> bool:
        """
        ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®

        Returns:
            æ˜¯å¦æˆåŠŸç¿»é¡µ
        """
        try:
            # æ ¹æ®ä½ æä¾›çš„ HTMLï¼ŒæŸ¥æ‰¾"ä¸‹ä¸€é¡µ"æŒ‰é’®
            next_button = self.driver.find_element(
                By.XPATH,
                "//a[contains(@class, 'weui-desktop-btn') and contains(text(), 'ä¸‹ä¸€é¡µ')]"
            )

            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»ï¼ˆä¸æ˜¯ disabled çŠ¶æ€ï¼‰
            if "disabled" in next_button.get_attribute("class"):
                return False

            next_button.click()
            time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
            return True

        except NoSuchElementException:
            logger.warning("æœªæ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®")
            return False
        except Exception as e:
            logger.error(f"ç¿»é¡µå¤±è´¥: {e}")
            return False

    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.driver:
            try:
                self.driver.quit()
                logger.info("âœ… æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")

    async def fetch_video_detail(self, video_url: str) -> Dict[str, Any]:
        """
        æŠ“å–å•ä¸ªè§†é¢‘è¯¦æƒ…ï¼ˆå¾…å®ç°ï¼‰

        Args:
            video_url: è§†é¢‘è¯¦æƒ…é¡µ URL

        Returns:
            è§†é¢‘è¯¦æƒ…æ•°æ®
        """
        # TODO: å®ç°è§†é¢‘è¯¦æƒ…æŠ“å–
        return {
            "success": False,
            "error": "è§†é¢‘è¯¦æƒ…æŠ“å–åŠŸèƒ½å¾…å®ç°",
            "platform": "wechat_channels"
        }
